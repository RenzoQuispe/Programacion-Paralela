### PageRank

El algoritmo PageRank es un algoritmo iterativo que se adapta bien al framework Spark. 
El objetivo del algoritmo es determinar qué páginas web son más importantes examinando los enlaces de una página a otras. En este algoritmo, el rango de una página, BBB, se define como sigue,
donde SRC(B)es el conjunto de páginas que contienen un enlace a BBB, mientras que
DEST_COUNT(A) es el número total de páginas a las que A enlaza. Intuitivamente, el algoritmo
PageRank funciona repartiendo el peso de una página A (es decir, RANK(A)) entre todas las
páginas a las que enlaza A (es decir, DEST_COUNT(A)). Cada página a la que enlaza A ve
incrementado su propio rango de forma proporcional al propio rango de A. Como resultado, las
páginas a las que se enlaza desde muchas páginas de alto rango también tendrán un alto rango.
La motivación para dividir la contribución de A en la suma por DEST_COUNT(A) es que si la
página A enlaza con varias páginas, cada una de las sucesoras debería obtener una fracción de la
contribución de la página A. A la inversa, si una página tiene muchos enlaces salientes, entonces
cada página sucesora obtiene una ponderación relativamente menor, en comparación con las
páginas que tienen menos enlaces salientes. Se trata de una definición recursiva en general, ya que
si (digamos) la página X enlaza con la página Y, y la página Y enlaza con la página X, entonces
RANK(X) depende de RANK(Y) y viceversa. Dada la naturaleza recursiva del problema, podemos
utilizar un algoritmo iterativo para calcular todos los rangos de las páginas actualizando
repetidamente los valores de los rangos utilizando la fórmula anterior y deteniéndonos cuando los
valores de los rangos hayan convergido a algún nivel aceptable de precisión. En cada iteración, el
nuevo valor de RANK(B), puede calcularse acumulando las contribuciones de cada página
predecesora, A. Puede obtenerse fácilmente una implementación paralela en Spark implementando
dos pasos en una iteración, uno para calcular las contribuciones de cada página a sus páginas
sucesoras utilizando el método flatMapToPair()flatMapToPair()y el segundo para calcular el rango
actual de cada página utilizando los métodos reduceByKey()reduceByKey() y
mapValues()mapValues(). Todos los resultados intermedios entre iteraciones se guardarán en la
memoria principal, lo que dará lugar a una ejecución mucho más rápida que una versión Hadoop
(que almacenaría los resultados intermedios en un almacenamiento externo).